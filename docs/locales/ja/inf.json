[
  {
    "id": "Llama.cpp",
    "title": "Llama.cpp - 効率的推論フレームワーク",
    "description": "Llama.cppは、多様なハードウェア上で効率的な実行を可能にするC/C++で書かれた大規模言語モデル（LLM）推論フレームワークです。GGMLエコシステムの一部として開発され、複数のハードウェアアーキテクチャに対するポータビリティと最適化で際立っています。\n\nフレームワークは外部依存関係のないミニマリストなインフラストラクチャを実装し、ネイティブC/C++のみを使用しています。このアプローチにより、クロスプラットフォームポータビリティ、各アーキテクチャに最適化されたパフォーマンス、リソース割り当ての細かい制御、バイナリサイズの削減を提供します。\n\n複数の精度をサポートする高度な量子化システムを実装：1.5ビットから8ビットまでの整数量子化、品質保持のための適応量子化アルゴリズム、精度とパフォーマンスのバランスを取るハイブリッド手法。\n\n複数のアーキテクチャをサポート：NEON最適化を備えたARM、AVX/AVX2/AVX512を備えたx86、CUDA/HIP/Metal/Vulkan経由のGPUアクセラレーション、専用NPU。GGUFフォーマットは効率的な読み込み、最適化された圧縮、自己完結型メタデータを提供します。\n\nエッジコンピューティング推論、オフライン環境、低レイテンシアプリケーション、コスト最適化シナリオに最適です。",
    "footer": "公式GGMLリポジトリに基づく技術文書"
  },
  {
    "id": "downloads",
    "title": "ダウンロード - LaPlace Attack AI",
    "description": "**開発中のプロジェクト**\n\nLaPlace Attack AIはまだダウンロードできません。これはLlama.cppベースのペンテストツール作成に焦点を当てた実験的プロジェクトです。\n\n**現在の状況：**\n• Webインターフェース：完了\n• 翻訳システム：実装済み\n• バックエンド：開発中\n• AIモデル：開発中\n\n**プロジェクトの目標：**\n• Linux用ペンテストツール\n• ポートとサービスのマッピング\n• 中級ハードウェア向けに最適化\n• インターネット依存なしのローカル実行\n\n**貢献方法：**\nこれはオープンソースプロジェクトです。セキュリティに応用されるAIに興味がある場合、GitHubリポジトリでの貢献を歓迎します。\n\n*プロジェクトは初期開発段階にあります。*",
    "footer": "© 2025 LaPlace - ペンテスト用ローカルAI"
  }
]
