[
  {
    "id": "Llama.cpp",
    "title": "Llama.cpp - あらゆるデバイス向けの軽量で高速なAI",
    "description": "Llama.cppは、Georgi Gerganovによって作成され、GGMLコミュニティによって維持されているオープンソースプロジェクトです。インターネットや外部サーバーに依存せずに、コンピューター上で人工知能モデルを効率的に実行できます。\n\nLlama.cppの特徴は、軽量でポータブルであることです。Windows、Linux、macOS、さらにはモバイルデバイスでも動作します。シンプルなマシンから高度なGPUまで、さまざまなタイプのハードウェアとの互換性と速度を保証するために、C/C++で記述されています。\n\n量子化技術のおかげで、Llama.cppは品質をあまり失うことなくモデルのサイズを削減できます。つまり、デバイスの能力に応じて、より小さく高速なバージョンと、より大きく正確なモデルの間で選択できます。\n\nプライバシー、低リソース消費、高パフォーマンスでAIをローカルで実行したい方に最適です。個人プロジェクト、研究、またはプロフェッショナルなアプリケーションにも適しています。",
    "footer": "Llama.cpp / GGMLリポジトリの公式ドキュメントに基づく"
  },
  {
    "id": "downloads",
    "title": "ダウンロード - LaPlace",
    "description": "LaPlaceは開発中で、まもなくダウンロード可能になります。私たちの目標は、さまざまなAIモデルを1つの場所に集約し、完全にカスタマイズ可能で使いやすいアプリケーションを提供することです。\n\n現在の状況：\n• アプリインターフェース：完了\n• 翻訳システム：準備完了\n• バックエンド：開発中\n• 統合されたAIモデル：進化中\n\nLaPlaceに期待できること：\n• インターネットに依存せずにAIモデルをローカルで実行\n• ミドルレンジマシンでも速度と効率性\n• さまざまな分野向けの統合作業環境（開発、ペネトレーションテスト、自動化など）\n• コミュニティとともに成長するオープンソースアプリ\n\n開発者、研究者、またはAI愛好家の方は、GitHubでプロジェクトをフォローして貢献できます。参加者が増えるほど、LaPlaceは早く完成します。",
    "footer": "© 2025 LaPlace - すべての人のためのオープンソースAI"
  }
]
