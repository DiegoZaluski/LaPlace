[
    {
        "id": "Llama.cpp",
        "title": "Llama.cpp - 高效推理框架",
        "description": "Llama.cpp是一个用C/C++编写的大型语言模型（LLM）推理框架，能够在多样化硬件上实现高效执行。作为GGML生态系统的一部分开发，以其可移植性和对多种硬件架构的优化而著称。\n\n该框架实现了无外部依赖的极简基础设施，专门使用原生C/C++。这种方法提供跨平台可移植性、针对每种架构的优化性能、对资源分配的精细控制以及减少的二进制大小。\n\n实现了支持多种精度的高级量化系统：从1.5位到8位的整数量化、用于质量保持的自适应量化算法，以及平衡精度和性能的混合方法。\n\n支持多种架构：具有NEON优化的ARM、具有AVX/AVX2/AVX512的x86、通过CUDA/HIP/Metal/Vulkan的GPU加速，以及专用NPU。GGUF格式提供高效加载、优化压缩和自包含元数据。\n\n适用于边缘计算推理、离线环境、低延迟应用和成本优化场景。",
        "footer": "基于官方GGML存储库的技术文档"
    },
    {
        "id": "downloads",
        "title": "下载 - LaPlace Attack AI",
        "description": "**项目开发中**\n\nLaPlace Attack AI尚未可供下载。这是一个专注于创建基于Llama.cpp的渗透测试工具的实验性项目。\n\n**当前状态：**\n• Web界面：已完成\n• 翻译系统：已实现\n• 后端：开发中\n• AI模型：开发中\n\n**项目目标：**\n• Linux渗透测试工具\n• 端口和服务映射\n• 针对中端硬件优化\n• 无需互联网依赖的本地执行\n\n**如何贡献：**\n这是一个开源项目。如果您对应用于安全的AI感兴趣，欢迎您在GitHub仓库中贡献。\n\n*项目处于早期开发阶段。*",
        "footer": "© 2025 LaPlace - 本地渗透测试AI"
    }
]